{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOrb0lNWXBkUSiBHsgkd0VU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kW8UDyp4S9vc","executionInfo":{"status":"ok","timestamp":1687626516175,"user_tz":-330,"elapsed":954,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}},"outputId":"6600c1f5-1914-4298-8353-e9f171b3b95e"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-24 17:08:34--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 172.217.214.128, 172.217.212.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 149574867 (143M) [application/zip]\n","Saving to: ‘horse-or-human.zip’\n","\n","horse-or-human.zip  100%[===================>] 142.65M   235MB/s    in 0.6s    \n","\n","2023-06-24 17:08:34 (235 MB/s) - ‘horse-or-human.zip’ saved [149574867/149574867]\n","\n"]}],"source":["!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"]},{"cell_type":"code","source":["import zipfile\n","\n","local_zip = './horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('./horse-or-human')\n","zip_ref.close()"],"metadata":{"id":"nLTdZ6a2TJsU","executionInfo":{"status":"ok","timestamp":1687626516886,"user_tz":-330,"elapsed":714,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","train_horse_dir=os.path.join('./horse-or-human/horses')\n","train_human_dir=os.path.join('./horse-or-human/humans')"],"metadata":{"id":"83PxIRUATkKV","executionInfo":{"status":"ok","timestamp":1687626516886,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_horse_names = os.listdir(train_horse_dir)\n","print(train_horse_names[:10])\n","\n","train_human_names = os.listdir(train_human_dir)\n","print(train_human_names[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpsOi_JDV3tz","executionInfo":{"status":"ok","timestamp":1687626516887,"user_tz":-330,"elapsed":6,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}},"outputId":"edbec54b-77b0-40da-8e86-222e8182e0fd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['horse46-7.png', 'horse33-5.png', 'horse26-9.png', 'horse20-2.png', 'horse29-0.png', 'horse06-4.png', 'horse10-6.png', 'horse27-7.png', 'horse03-9.png', 'horse34-1.png']\n","['human16-19.png', 'human07-12.png', 'human09-01.png', 'human16-01.png', 'human08-27.png', 'human10-01.png', 'human12-07.png', 'human10-13.png', 'human10-07.png', 'human07-29.png']\n"]}]},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","nrows=4\n","ncols=4\n","pic_index=0"],"metadata":{"id":"JUM_tmvVV6tH","executionInfo":{"status":"ok","timestamp":1687626516887,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["fig = plt.gcf()\n","fig.set_size_inches(ncols * 4, nrows * 4)\n","\n","pic_index += 8\n","next_horse_pix = [os.path.join(train_horse_dir, fname)\n","                for fname in train_horse_names[pic_index-8:pic_index]]\n","next_human_pix = [os.path.join(train_human_dir, fname)\n","                for fname in train_human_names[pic_index-8:pic_index]]\n","\n","for i, img_path in enumerate(next_horse_pix+next_human_pix):\n","\n","  sp = plt.subplot(nrows, ncols, i + 1)\n","  sp.axis('Off')\n","\n","  img = mpimg.imread(img_path)\n","  plt.imshow(img)\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":913,"output_embedded_package_id":"1pyjEew94ekKypomExC45mdVyNTXrE6Vd"},"id":"UyHGU2t4WOz1","executionInfo":{"status":"ok","timestamp":1687626520765,"user_tz":-330,"elapsed":3882,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}},"outputId":"56208237-0a99-4107-e4de-0e0999d78de3"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import tensorflow as tf\n"],"metadata":{"id":"jod0ijNkWYVn","executionInfo":{"status":"ok","timestamp":1687626521376,"user_tz":-330,"elapsed":618,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","\n","    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    tf.keras.layers.Flatten(),\n","\n","    tf.keras.layers.Dense(512, activation='relu'),\n","\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"metadata":{"id":"uCb9SDQUWdgc","executionInfo":{"status":"ok","timestamp":1687626524792,"user_tz":-330,"elapsed":3418,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model.summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1mBc2LPWlTU","executionInfo":{"status":"ok","timestamp":1687626524792,"user_tz":-330,"elapsed":6,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}},"outputId":"e4ef6270-e8aa-4cc5-c7f8-d71941e9d2bb"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x7f94664be9e0>>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss='binary_crossentropy',optimizer=RMSprop(learning_rate=0.001),metrics=['accuracy'])"],"metadata":{"id":"rN99SIu4WoQJ","executionInfo":{"status":"ok","timestamp":1687626524792,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","train_datagen=ImageDataGenerator(1./255.0)"],"metadata":{"id":"BVKm9B9rXB4f","executionInfo":{"status":"ok","timestamp":1687626524792,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["train_generator=train_datagen.flow_from_directory(\n","    './horse-or-human/',target_size=(300,300),batch_size=128,class_mode='binary')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDTvDMB0XPKq","executionInfo":{"status":"ok","timestamp":1687626524793,"user_tz":-330,"elapsed":6,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}},"outputId":"a6206ff8-9bc1-4964-ee76-7fb049ae6ef9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1027 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","      train_generator,\n","      steps_per_epoch=8,\n","      epochs=15,\n","      verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59OMT0kVXlAa","executionInfo":{"status":"ok","timestamp":1687626662647,"user_tz":-330,"elapsed":137859,"user":{"displayName":"Chandan Satwani","userId":"05765873213925401627"}},"outputId":"1d9c5adf-446c-45ec-c5e6-c0ab9ac567fc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","8/8 [==============================] - 21s 861ms/step - loss: 4.4859 - accuracy: 0.5128\n","Epoch 2/15\n","8/8 [==============================] - 7s 797ms/step - loss: 0.7065 - accuracy: 0.6073\n","Epoch 3/15\n","8/8 [==============================] - 6s 753ms/step - loss: 0.4034 - accuracy: 0.8209\n","Epoch 4/15\n","8/8 [==============================] - 8s 913ms/step - loss: 0.1498 - accuracy: 0.9521\n","Epoch 5/15\n","8/8 [==============================] - 8s 935ms/step - loss: 0.0685 - accuracy: 0.9746\n","Epoch 6/15\n","8/8 [==============================] - 7s 793ms/step - loss: 0.0143 - accuracy: 0.9978\n","Epoch 7/15\n","8/8 [==============================] - 6s 762ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 8/15\n","8/8 [==============================] - 7s 763ms/step - loss: 0.6536 - accuracy: 0.9066\n","Epoch 9/15\n","8/8 [==============================] - 7s 836ms/step - loss: 0.8988 - accuracy: 0.7475\n","Epoch 10/15\n","8/8 [==============================] - 6s 758ms/step - loss: 0.1876 - accuracy: 0.9499\n","Epoch 11/15\n","8/8 [==============================] - 7s 805ms/step - loss: 0.0238 - accuracy: 0.9922\n","Epoch 12/15\n","8/8 [==============================] - 7s 830ms/step - loss: 0.3004 - accuracy: 0.9622\n","Epoch 13/15\n","8/8 [==============================] - 6s 774ms/step - loss: 1.3559 - accuracy: 0.7141\n","Epoch 14/15\n","8/8 [==============================] - 7s 831ms/step - loss: 0.1484 - accuracy: 0.9444\n","Epoch 15/15\n","8/8 [==============================] - 7s 826ms/step - loss: 0.1448 - accuracy: 0.9455\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from google.colab import files\n","from tensorflow.keras.utils import load_img, img_to_array\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","\n","  # predicting images\n","  path = '/content/' + fn\n","  img = load_img(path, target_size=(300, 300))\n","  x = img_to_array(img)\n","  x /= 255\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=10)\n","  print(classes[0])\n","\n","  if classes[0]>0.5:\n","    print(fn + \" is a human\")\n","  else:\n","    print(fn + \" is a horse\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38},"id":"2hzyH70aXsRp","outputId":"db8b43ca-2deb-469b-976d-f625ba80f288"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a43d28d8-b14d-470c-adc8-15eb9aa87d87\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a43d28d8-b14d-470c-adc8-15eb9aa87d87\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]}]}